{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-20T04:17:21.322079Z",
     "start_time": "2021-10-20T04:17:19.190711Z"
    }
   },
   "outputs": [],
   "source": [
    "# import module\n",
    "import m as a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T14:11:17.770167Z",
     "start_time": "2021-10-21T14:11:15.275681Z"
    }
   },
   "outputs": [],
   "source": [
    "# import library\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import pandas_datareader as web\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# sklearn libraries\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import (train_test_split,\n",
    "                                     cross_validate,\n",
    "                                     GridSearchCV\n",
    "                                    )\n",
    "from sklearn.metrics import (r2_score, \n",
    "                             mean_squared_error\n",
    "                            )\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "from sklearn.utils.validation import (check_array, \n",
    "                                      check_is_fitted, \n",
    "                                      check_X_y,\n",
    "                                      _check_sample_weight\n",
    "                                     )\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T06:28:25.407848Z",
     "start_time": "2021-10-12T06:28:25.395174Z"
    }
   },
   "outputs": [],
   "source": [
    "class SupportVectorReg(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    This is an example of the support vector machine regression class written from scratch.\n",
    "    \"\"\"\n",
    "    test_size = 0.3\n",
    "    random_state = 42\n",
    "    missing_vals = 10\n",
    "    \n",
    "    def __init__(self,\n",
    "                 X:pd.DataFrame,\n",
    "                 y:list,\n",
    "                 base_regressor = SVR\n",
    "                 kernel:str = None,\n",
    "                 degree:int = 3,\n",
    "                 gamma:float = 1.0,\n",
    "                 coef0:float = 0.0,\n",
    "                 C:float = 1.0,\n",
    "                 epsilon:float = 0.1,\n",
    "                 verbose:bool = False,\n",
    "                 max_iter:int = 1000):\n",
    "        \n",
    "        BaseEstimator.__init__(self)\n",
    "        TransformerMixin.__init__(self)\n",
    "        \n",
    "        self.base_regressor = base_regressor()\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.kernel = self.fkernel(kernel, **kwargs)\n",
    "        self.degree = degree\n",
    "        self.gamma = gamma # specified further in fit method\n",
    "        self.coef0 = coef0\n",
    "        self.epsilon = epsilon\n",
    "        self.verbose = verbose\n",
    "        self.max_iter = max_iter\n",
    "        \n",
    "        if self.C is None:\n",
    "            self.C = C\n",
    "        else:\n",
    "\n",
    "        # model parameters set to None (I have to come up with them later)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "\n",
    "        \n",
    "        \n",
    "    def fkernel(self, kernel:str = None, **kwargs):\n",
    "        \n",
    "        if not kernel:\n",
    "            pass\n",
    "        \n",
    "        if kernel:\n",
    "            if kernel == \"linear\":\n",
    "                def linear_kernel():\n",
    "                    return lambda X,y: np.dot(X,y.T)\n",
    "        \n",
    "            if kernel == \"poly\":\n",
    "                def _polynomial_kernel(bias = 0, power = 2):\n",
    "                    return lambda X,y: (self.gamma * np.dot(X,y)+bias)**power\n",
    "        \n",
    "            if kernel == \"rbf\":\n",
    "                def _rbf_kernel():\n",
    "                    return lambda X_i,y_i: np.exp(-self.gamma * np.dot(X_i-y_i, X_i-y_i))  \n",
    "        \n",
    "        \n",
    "        kernel_mapping = {\n",
    "            \"linear\": _linear_kernel,\n",
    "            \"poly\": _polynomial_kernel,\n",
    "            \"rbf\": _rbf_kernel\n",
    "        }\n",
    "            \n",
    "    \n",
    "        if kernel not in kernel_mapping.keys():\n",
    "            raise ValueError(\n",
    "                \"The provided kernel {} is invalid. Choose from the following {}.\".format(\n",
    "                    kernel, list(kernel_mapping.keys())\n",
    "                )\n",
    "            )\n",
    "    \n",
    "        return \n",
    "      \n",
    "        \n",
    "    def decorator_function(original_function):\n",
    "        def wrapper_function(*args, **kwargs):\n",
    "            print(\"wrapper executed this before {}\".format(original_function))\n",
    "            return original_function(*args, **kwargs)\n",
    "        return wrapper_function\n",
    "    \n",
    "    original_function = decorator_function(original_function)\n",
    "    original_function()   \n",
    "    \n",
    "    \n",
    "    @decorator_function\n",
    "    def create_Xy(self, X:float, y:float): # tells the reader that it should be float\n",
    "        \"\"\"\n",
    "        The below function sets the dependent and independent variables.\n",
    "        \"\"\"\n",
    "        \n",
    "        X = np.array(\n",
    "            t.bollinger_bands()[\n",
    "                [\"Bollinger Bands Lower\", \"Bollinger Bands Middle\", \"Bollinger Bands Upper\"]\n",
    "                                ]).reshape(-1,3)\n",
    "        \n",
    "        y = np.array(ticker[\"Close\"]).reshape(len(ticker[\"Close\"]),1) # or -1   \n",
    "\n",
    "        \n",
    "    @decorator_function\n",
    "    def feature_scaling(self):\n",
    "        \"\"\"\n",
    "        The following function scales the data. Step 2: Data pre-processing. \n",
    "        \"\"\"\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        \n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        y_train = scaler.fit_transform(y_train)\n",
    "        \n",
    "        \n",
    "    def train_test_split(self, X:np.ndarray, y:np.ndarray):    \n",
    "        \"\"\"\n",
    "        The following function splits the data into train and test set. Step 3: feature engineering. \n",
    "        \"\"\"\n",
    "        X = X.values.reshape(-1,1) # -1 unknown dimension and we want numpy to figure it out, 1 column and numpy figures out the number of rows\n",
    "        y = y.values.reshape(-1,1)\n",
    "        \n",
    "        # reshape must be done before train test split so that X,y are passed in the format required (1 col and many rows)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                            y, \n",
    "                                                            test_size = SupportVectorRegression.test_size, \n",
    "                                                            random_state = SupportVectorRegression.random_state,\n",
    "                                                            stratify = y\n",
    "                                                           )\n",
    "        # Setting ‘stratify’ to y makes our training split represent the proportion of each value in the y variable. \n",
    "        # For example, in our dataset, if 25% of patients have diabetes and 75% don’t have diabetes, setting ‘stratify’ to y will ensure \n",
    "        # that the random split has 25% of patients with diabetes and 75% of patients without diabetes.\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    \n",
    "    def fit(self, X_train:np.ndarray, y_train:np.ndarray):\n",
    "        \"\"\"\n",
    "        The below function fits the model on the training data. Step 4: fit the model. \n",
    "        \"\"\"\n",
    "        if y is None:\n",
    "            raise ValueError(\"target variable not defined\")\n",
    "        \n",
    "        \n",
    "        X_train, y_train = train_test_split()\n",
    "        \n",
    "        y_ = np.where(y <= 0, -1,1)\n",
    "        \n",
    "        SupportVectorReg = SVR(kernel = self.kernel,\n",
    "                               degree = self.degree,\n",
    "                               gamma = self.gamma,\n",
    "                               coef0 = self.coef0,\n",
    "                               tol = 0.001,\n",
    "                               C = self.C,\n",
    "                               epsilon = self.epsilon,\n",
    "                               verbose = False,\n",
    "                               max_iter = -1 \n",
    "                              )\n",
    "        \n",
    "        SupportVectorReg.fit(X_train, y_train)\n",
    "        \n",
    "        \n",
    "        self.base_regressor.fit(X,y)\n",
    "        \n",
    "        \n",
    "        if self.fit_intercept:\n",
    "            self.intercept_ = coef0\n",
    "            self.coef_ = coefs[1:]\n",
    "        else:\n",
    "            self.intercept_ = 0\n",
    "            self.coef_ = coefs\n",
    "        \n",
    "        \n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        # if gamma is not specified in init, it is specified as below\n",
    "        if not self.gamma:\n",
    "            self.gamma = 1/(n_features*X.var())\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        return self\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def predict(self, X_test:np.array, y = None):\n",
    "        if not y:\n",
    "            \n",
    "            check_is_fitted(self) # checks trailing underscore         \n",
    "            X = check_array(X)\n",
    "            y_pred = self.base_regressor.predict(X_test)\n",
    "        \n",
    "        return y_pred\n",
    "        \n",
    "    def evaluation(self):\n",
    "        \"\"\"\n",
    "        The following function evaluates how well the model performs on the test data. Step 6: model evaluation. \n",
    "        \"\"\"\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        return rmse\n",
    "    \n",
    "    def check(self):\n",
    "        X = check_array(X)\n",
    "        if X.shape[1] != self.n_features:\n",
    "            raise ValueError(\"{} != {}\".format(X.shape[1], self.n_features))\n",
    "            \n",
    "    def f(self):\n",
    "        for i, n in range(self.max_iter):\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def missing_val(self, X, verbose = True):\n",
    "        missing_val = [len(isnull(X[:,i])) for i in range(X.shape[1])]\n",
    "        if verbose:\n",
    "            print(\"Missing vals %s\" % missing_val)\n",
    "        \n",
    "        delete = [i for i,v in enumerate(missing_val) if v >= SupportVectorRegression.missing_vals]\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"Deleting %s\" % delete)\n",
    "        \n",
    "        if len(delete) is 0:\n",
    "            return X\n",
    "# select all columns except the ones that have missing values\n",
    "\n",
    "    notMisVals = [i for i in range(X.shape[1]) if i not in delete]\n",
    "    result = X[:, notMisVals]\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_params(self, deep = True):\n",
    "        \"\"\"\n",
    "        The below function returns parameter values.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"C\": self.C,\n",
    "            \"kernel\": self.kernel\n",
    "            \"epsilon\": self.epsilon\n",
    "        }\n",
    "    \n",
    "    def set_params(self, **params):\n",
    "        for param, val in params.items():\n",
    "            setattr(self, param, val)\n",
    "        return self    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and test abstract class\n",
    "if __name__ == \"__main__\":\n",
    "    ticker = \"ES=F\" #snp500 futures\n",
    "    end = datetime.today()\n",
    "    start = datetime(end.year-1, end.month, end.day)\n",
    "    ticker = web.DataReader(ticker, \"yahoo\", start, end)\n",
    "    \n",
    "    X = \n",
    "    y = \n",
    "    \n",
    "    model = SupportVectorRegression()\n",
    "    model.fit()\n",
    "    model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T04:30:05.830381Z",
     "start_time": "2021-10-08T04:30:04.945245Z"
    }
   },
   "outputs": [],
   "source": [
    "# t = a.TechnicalIndicators(ticker[\"Close\"], ticker[\"High\"], ticker[\"Low\"], ticker[\"Volume\"])\n",
    "\n",
    "# t = a.TechnicalIndicators(ticker[\"Close\"], ticker[\"High\"], ticker[\"Low\"], ticker[\"Volume\"])\n",
    "# df = pd.DataFrame(t)\n",
    "\n",
    "# t.set_technical_indicators()\n",
    "# t.rsi()\n",
    "# t.rate_change()\n",
    "# t.stochastic_oscillator()\n",
    "# t.WilliamsR()\n",
    "\n",
    "# t.macd()\n",
    "# t.ema()\n",
    "# t.wma()\n",
    "# t.moving_average()\n",
    "\n",
    "# t.bollinger_bands()\n",
    "# t.average_true_range()\n",
    "\n",
    "# t.on_balance_volume()\n",
    "# t.money_flow_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T04:27:22.749359Z",
     "start_time": "2021-10-08T04:27:22.742125Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T04:31:00.272617Z",
     "start_time": "2021-10-08T04:31:00.259799Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T03:52:11.745128Z",
     "start_time": "2021-10-08T03:52:11.736475Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-08T04:34:59.342497Z",
     "start_time": "2021-10-08T04:34:59.331701Z"
    }
   },
   "outputs": [],
   "source": [
    "np.array(ticker[\"Close\"]).reshape(len(ticker[\"Close\"]),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"C: {}\".format(fitted_svr_model.C))\n",
    "#     print(\"Epsilon: {}\".format(fitted_svr_model.epsilon))\n",
    "    \n",
    "#     sc_X = StandardScaler()\n",
    "# sc_y = StandardScaler()\n",
    "# X_train = sc_X.fit_transform(X_train)\n",
    "# y_train = sc_y.fit_transform(y_train)\n",
    "\n",
    "# X_test = sc_X.fit_transform(X_test)\n",
    "# y_test = sc_y.fit_transform(y_test)\n",
    "\n",
    "# np.dot\n",
    "\n",
    "# \"\"\"\n",
    "#         Parameters:\n",
    "#         - kernel:   string indicating kernel \"linear\", \"poly\", \"rbf\", default \"rbf\" see above\n",
    "#                     transforms train data so that data that cannot be linearly separated \n",
    "#                     are now linearly separated in a higher number of dimension spaces\n",
    "#         - degree:\n",
    "#         - gamma:\n",
    "#         - coef0:\n",
    "#         - C:\n",
    "#         - epsilon: The value defines a margin of tolerance where no penalty is given to errors. \n",
    "#                    The larger it is, the larger errors you admit in your solution.\n",
    "#         - verbose: output messages, useful for debugging or understading how the training performs\n",
    "#         - max_iter: -1 for no limit\n",
    "#         \"\"\"        \n",
    "\n",
    "#     def param_list(self):\n",
    "#         \"\"\"\n",
    "#         The following function returns the list of parameters and the respective values.\n",
    "#         \"\"\"\n",
    "#         return {\"C\": self.C, \n",
    "#                 \"kernel\": self.kernel, \n",
    "#                 \"gamma\": self.gamma}\n",
    "\n",
    "#     def param_grid(self):\n",
    "        \n",
    "#         param_grid = {'C': [ 1, 10, 100, 1000,10000], \n",
    "#               'gamma': [1,0.1,0.01,0.001,0.0001],\n",
    "#               'kernel': ['rbf']}\n",
    "        \n",
    "#         pass\n",
    "#  if (kernel is None): # set rbf to default\n",
    "#             self.kernel = \"rbf\" \n",
    "#         else:\n",
    "#             self.kernel = kernel\n",
    "\n",
    "print(\"Accuracy: {}%\".format(clf.score(X_test, y_test) * 100 ))\n",
    " if kernel == \"poly\":\n",
    "            self.kernel = self._polynomial_kernel\n",
    "            self.degree = degree\n",
    "        elif kernel == \"rbf\":\n",
    "            self.kernel = self._rbf_kernel\n",
    "            self.sigma = sigma\n",
    "        elif kernel = \"linear\":\n",
    "            self.kernel = self_linear_kernel\n",
    "        else: self.kernel = kernel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
