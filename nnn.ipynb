{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b287cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "random.seed(43)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdb3b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate random data with seed for reproducibility\n",
    "#input matrix of shape (1000,4)\n",
    "np.random.seed(43)\n",
    "a = np.random.randn(1000,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54891d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate random data with seed for reproducibility\n",
    "#output vector of shape (1000,1)\n",
    "np.random.seed(43)\n",
    "b = np.random.randn(1000,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ae3d7e",
   "metadata": {},
   "source": [
    "$$J = -\\frac{1}{m}\\sum\\limits_{i=1}^{m}y_i \\ln(a_i)+(1-y_i)\\ln(1-a_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf5251b",
   "metadata": {},
   "source": [
    "$$A = \\sigma(w^{T}x + b)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c87f20",
   "metadata": {},
   "source": [
    "$$ \\frac{\\partial J}{\\partial w} = \\frac{1}{m}X(A-Y)^T$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4fb4ee",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial J}{\\partial b} = \\frac{1}{m}\\sum\\limits_{i=1}^{m}(a_i - y_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae3724c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class nn(object):\n",
    "    \"\"\"\n",
    "    Class constructor.\n",
    "    \"\"\"\n",
    "    def __init__(self,x0:np.ndarray,y0:np.ndarray,lr:float=0.001,n_iters:int=1000):\n",
    "        \"\"\"\n",
    "        Constructor method.\n",
    "        \"\"\"\n",
    "        self.x0 = x0\n",
    "        self.y0 = y0\n",
    "        assert(type(x0)==np.ndarray and type(y0)==np.ndarray)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.lr = lr\n",
    "        self.n_iters = n_iters\n",
    "        \n",
    "        \n",
    "        self.m, self.n = np.shape(self.x0)[0], np.shape(self.x0)[1]\n",
    "    \n",
    "    \n",
    "        #initialise parameters \n",
    "        #weight column vector of shape (4,1)\n",
    "        self.w = np.random.randn(self.n,1)\n",
    "        self.b = 0\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    def create_array(self):\n",
    "        \"\"\"Creates a list\n",
    "        :return:\n",
    "        :rtype: list\n",
    "        \"\"\"\n",
    "        \n",
    "        self.array = []\n",
    "        \n",
    "        return self.array\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def sigmoid(self,z):\n",
    "        \"\"\"Non-linear activation function.\n",
    "        :return: \n",
    "        :rtype: \n",
    "        \"\"\"\n",
    "        return 1/(1+np.exp(-z))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def forward_propagate_vectorised(self):\n",
    "        \"\"\"Forward propagation. Vectorised Implementation.\n",
    "        :return: \n",
    "        :rtype: \n",
    "        \"\"\"\n",
    "    \n",
    "        #number of cols in first array must equal the number of rows in second array\n",
    "        if np.shape(self.x0)[1] == np.shape(self.w)[0]:\n",
    "            \n",
    "            #matrix multiplication input matrix and weights\n",
    "            #b is a scalar bias parameter\n",
    "            #shape (1000,4) and (4,1), then result A of shape (1000,1)\n",
    "            #pass into static sigmoid function defined above\n",
    "            A = self.sigmoid(np.matmul(self.x0,self.w)+self.b)\n",
    "            \n",
    "            \n",
    "            #vector A of shape (1000,1) must be equal to (1000,1)\n",
    "            #to check if A calculated correctly\n",
    "            if np.shape(A) == (np.size(self.x0,0),np.size(self.w,1)):\n",
    "            \n",
    "            \n",
    "                #cost function J in vectorised form\n",
    "                #mathematical formula defined above\n",
    "                cost = (-1/self.m)*np.sum(self.y0*np.log(A)+(1-self.y0)*(np.log(1-A)))\n",
    "            \n",
    "            \n",
    "            \n",
    "                #calculate gradients of the cost function w.r.t. parameters\n",
    "                #mathematical formula defined above\n",
    "                #A is of shape (1000,1)\n",
    "                #self.y0 output vector is of shape (1000,1)\n",
    "                #self.x0 is of shape (1000,4)\n",
    "                #matrix multiplication can only be calc if num of cols if\n",
    "                #num of cols in first matrix is equal to num of rows in second matrix\n",
    "                #hence self.x0.T is of shape (4,1000)\n",
    "                #resulting d_w is then of shape (4,1)\n",
    "                d_w = (1/self.m)*np.matmul(self.x0.T,(A-self.y0))\n",
    "                \n",
    "                #divide by 1 over num of samples\n",
    "                d_b = (1/self.m)*np.sum(A-self.y0)\n",
    "        \n",
    "                #store gradients in a dict\n",
    "                gradients = {\n",
    "                        \"d_w\":d_w,\n",
    "                        \"d_b\":d_b\n",
    "                    }\n",
    "                \n",
    "             \n",
    "            else:\n",
    "                print(f\"must be of shape ({np.size(self.x0,0)},{np.size(self.w,1)})\")\n",
    "                \n",
    "        #number of cols in first array not equal the number of rows in second array\n",
    "        #matrix multiplication cannot be calculated\n",
    "        else:\n",
    "            \n",
    "            print(f\"{np.shape(self.x0)[1]} not equal to {np.shape(self.w)[0]}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        return cost, gradients\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def forward_propagate_not_vectorised(self):\n",
    "        \"\"\"Forward propagation. Non-Vectorised Implementation.\n",
    "        :return: \n",
    "        :rtype: \n",
    "        \"\"\"\n",
    "        \n",
    "        #matrix multiplication input matrix of shape (1000,4) and weight column vector (4,1)\n",
    "        #resulting vector B_p is then of shape (1000,1)\n",
    "        #hence first initialise B_p to zeros of shape (1000,1)\n",
    "        B_p = np.zeros(\n",
    "                (np.size(self.x0,0),np.size(self.w,1))\n",
    "            )\n",
    "        \n",
    "        \n",
    "        #number of cols in first array must equal the number of rows in second array\n",
    "        #if true, then matrix multiplication of self.x0 and self.w\n",
    "        if np.shape(self.x0)[1] == np.shape(self.w)[0]:\n",
    "        \n",
    "        \n",
    "            for i in range(len(self.x0)):\n",
    "        \n",
    "                for j in range(len(self.w[0])):\n",
    "        \n",
    "                    for k in range(len(self.w)):\n",
    "        \n",
    "                        B_p[i][j] += self.x0[i][k]*self.w[k][j]\n",
    "        \n",
    "            #add scalar bias term to the result and pass to sigmoid function\n",
    "            #B of shape (1000,1)\n",
    "            B = self.sigmoid(B_p + self.b)\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #cost function J in non-vectorised form\n",
    "        #mathematical formula defined above\n",
    "        #c_ is equal to cost J, iterate over every sample\n",
    "        #self.y0 and B are both of shape (1000,1)\n",
    "        #result c_ is a scalar because it is not indexed by m\n",
    "        c_ = 0\n",
    "        for m in range(self.m):\n",
    "            c_ += (self.y0[m]*np.log(B[m])+(1-self.y0[m])*(np.log(1-B[m])))\n",
    "        \n",
    "        \n",
    "        cost = (-1/self.m)*c_\n",
    "        cost = float(cost)\n",
    "        \n",
    "        \n",
    "        #d_w1 = (1/self.m)*np.matmul((self.x0).T,(B-self.y0))\n",
    "        \n",
    "        #derivative of the cost function w.r.t. w in non-vectorised form\n",
    "        #first matrix substraction B - self.y0, both shape (1000,1)\n",
    "        #result K also of shape (1000,1)\n",
    "        #initialise K with zeros of shape (1000,1)\n",
    "        \n",
    "        K = np.zeros(\n",
    "                (np.size(B,0),np.size(self.y0,1))\n",
    "            )\n",
    "        \n",
    "        for u in range(self.m):\n",
    "            K[u] += B[u] - self.y0[u]\n",
    "        \n",
    "        \n",
    "        #K is of shape (1000,1) and self.x0 of shape (1000,4)\n",
    "        #transpose self.x0 for matrix multiplication in non-vectorised form\n",
    "        #then self.x0.T of shape (4,1000) and K of shape (1000,1)\n",
    "        #resulting L is of shape (4,1)\n",
    "        \n",
    "        L = np.zeros((np.size(self.x0.T,0),np.size(K,1)))\n",
    "        \n",
    "        for m in range(len(self.x0.T)):\n",
    "        \n",
    "            for n in range(len(K[0])):\n",
    "        \n",
    "                for k in range(len(K)):\n",
    "        \n",
    "                    L[m][n] += self.x0.T[m][k]*K[k][n]\n",
    "        \n",
    "        \n",
    "        d_w1 = (1/self.m)*L\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #derivative of the cost function w.r.t. b in non-vectorised form\n",
    "        # result is a scalar hence initialise to zero\n",
    "        #notice d_b1 is not indexed by e\n",
    "        #iterate over each row in input data\n",
    "        #both B and self.y0 are of shape (1000,1)\n",
    "        d_b1 = 0\n",
    "        \n",
    "        for e in range(self.m):\n",
    "            \n",
    "            d_b1 += B[e]-self.y0[e]\n",
    "        \n",
    "        d_b1 = (1/self.m)*d_b1\n",
    "        d_b1 = float(d_b1)\n",
    "        \n",
    "        \n",
    "        #store gradients in a dict\n",
    "        gradients = {\n",
    "                \"d_w1\":d_w1,\n",
    "                \"d_b1\":d_b1\n",
    "            }\n",
    "        \n",
    "        return cost, gradients\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def gradient_descent(self):\n",
    "        \"\"\"The below functions runs gradient descent.\n",
    "        :return: Optimal parameters w,b\n",
    "        :rtype: np.array\n",
    "        \"\"\"\n",
    "        \n",
    "        costs = self.create_array()\n",
    "        \n",
    "        \n",
    "        for i in range(self.n_iters):\n",
    "                \n",
    "            j, k = self.forward_propagate_vectorised()\n",
    "            \n",
    "            self.w = self.w - self.lr*k[\"d_w\"]\n",
    "            self.b = self.b - self.lr*k[\"d_b\"]\n",
    "    \n",
    "            costs.append(j)\n",
    "            \n",
    "            if i % 100 ==0:\n",
    "                print(f\"Costs after iter {i}:{j}\")\n",
    "        \n",
    "        optim_params = {\n",
    "            \"w\": self.w,\n",
    "            \"b\": self.b\n",
    "            }\n",
    "        \n",
    "        plt.plot(costs)\n",
    "        \n",
    "        return optim_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a6813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_nets = nn(a,b,0.005,2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87036383",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_nets.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a997e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_nets.forward_propagate_vectorised()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4af58aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_nets.forward_propagate_not_vectorised()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b477ae6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_nets.gradient_descent()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
